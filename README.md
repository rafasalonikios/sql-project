# Positioning Skechers Against its Peers in the Shoe Market
## Project Objective
The main problem is understanding the market of shoes, their prices and online ratings, and determine how that is related to size and gender. This will ultimately provide me with the opportunity of recommeding some actions to Skechers (job I am applying to) on how they can take advantage of some of these market trends and how the company should position itself, compared to its peers in the industry.
I am using Python and SQL to collect and analyze the data and hopefully, find some interesting insights on the main problem described.
## Job Description
Skechers, a leader in the footwear industry headquartered in Southern California, is looking for a business inteligence analyst, role that involves enhancing the Direct to Consumer strategy through data analytics and insights. Analytic solution are expected to be implemented and data analysis to support the decision making process. 
By using Python and SQL to do the project, it will provide similar insights as the one someone will have to reach on the described role. The project, as well as the role at Skechers, involves a lot of technical skills and abilities to be analytical, providing insights. 
## Data
The data used to do this project has 2 different sources: the first one gathered through an API from a Kaggle dataset called Shoe Prices Dataset. It compares many different shoes from different brands and its prices. The second source of data used was through scrapping a website called "Zappos", a shoe store. The code I wrote basically scrapes relevant information from the brands that appear on the previous dataset, such as name, price and rating.
## Notebooks
I used 2 Jupyter notebooks on Google colab. The first one API_ETL.ipynb (https://colab.research.google.com/drive/1kfiLfzFhNbaHfXOTC9CZ0Lfe8r9A7mVA?usp=sharing) that gets the data from the Kaggle dataset through an API. There are also a few visualizations that I thought were relevant for the end of the project. The second Jupyter notebook is called Web_Scrape_ETL.ipynb (https://colab.research.google.com/drive/1LJb59BH6WhAiHsN1H_bw8Mwp1T0f5uKT?usp=sharing) and is basically used to scrape the data from the website I mentioned and transfer that data over to DBeaver, just like the API notebook as well.
## Improvements
If I had more time I would have probably tried to find datasets that are easier to relate to each other. These are both about shoes but on different products and obtained data that wasn't really connected.
